# üìä Pipeline ETL Censo: Rendimento e Desigualdade

Este reposit√≥rio documenta um pipeline de Engenharia de Dados que processa dados brutos de um Censo Demogr√°fico para calcular indicadores de Rendimento M√©dio Mensal. O projeto √© um exemplo pr√°tico da Arquitetura Medallion implementada em um ambiente PostgreSQL (ELT) e consultada via PySpark/Databricks.

## 1\. Contexto, Tecnologia e Metodologia do Projeto

### 1.1. Motiva√ß√£o e Objetivos

O principal objetivo deste projeto √© transformar dados complexos e sujos de um Censo em uma estrutura anal√≠tica limpa. A finalidade √© permitir que analistas de BI e Ci√™ncia de Dados gerem *insights* r√°pidos sobre **disparidade de rendimento** e **comportamento demogr√°fico** (incluindo vari√°veis como Sexo, Cor/Ra√ßa e, em an√°lises secund√°rias, Meios de Transporte). O pipeline garante que a base de consumo final seja imut√°vel e confi√°vel.

### 1.2. Stack Tecnol√≥gico

| Ferramenta | Uso no Projeto |
| :--- | :--- |
| **PostgreSQL** | Motor central do ELT, gerenciamento de schemas e persist√™ncia das camadas Bronze, Silver e Gold. |
| **PySpark / Databricks** | Ambiente de desenvolvimento para valida√ß√£o de dados (Auditoria) e consultas anal√≠ticas explorat√≥rias (ad-hoc). |
| **SQL (ANSI)** | Linguagem prim√°ria para todas as transforma√ß√µes de dados entre as camadas (limpeza, tipagem, agrega√ß√£o). |
| **Markdown / Git** | Documenta√ß√£o e controle de vers√£o do pipeline. |

### 1.3. Abordagem Metodol√≥gica

1.  **Arquitetura Medallion (Bronze/Silver/Gold):** Estrat√©gia adotada para promover a qualidade e rastreabilidade do dado. O dado evolui da forma bruta (Bronze) at√© o formato de BI (Gold).
2.  **Star Schema (Camada Gold):** Modelagem dimensional utilizada na camada de consumo. A Tabela Fato (`fato_indicadores`) centraliza os indicadores de rendimento, e as dimens√µes (`dim_categorias`, `dim_geografia`) fornecem o contexto necess√°rio, simplificando as consultas de BI.
3.  **C√°lculo de Rendimento:** A transforma√ß√£o cr√≠tica de `renda_total_nominal / populacao_ocupada` √© feita na camada **Silver** com tratamento obrigat√≥rio de divis√£o por zero (`NULLIF(populacao_ocupada, 0)`), garantindo que a Camada Gold s√≥ receba valores v√°lidos ou `NULL` (em vez de erros de execu√ß√£o).

-----

## 2\. Pipeline ELT em PostgreSQL (Detalhado)

### 2.1. Configura√ß√£o e Ingest√£o BRONZE

```sql
-- Cria√ß√£o dos Schemas (As tr√™s camadas)
CREATE SCHEMA IF NOT EXISTS bronze;
CREATE SCHEMA IF NOT EXISTS silver;
CREATE SCHEMA IF NOT EXISTS gold;

-- 1. Cria√ß√£o da Tabela BRONZE (Entrada de Dados Brutos)
DROP TABLE IF EXISTS bronze.censo CASCADE;
CREATE TABLE bronze.censo (
    source_file TEXT, area_km2 TEXT, densidade_demografica_hab_km2 TEXT, 
    renda_total_nominal TEXT, populacao_ocupada TEXT, sexo TEXT TEXT, cor_ou_raca TEXT
);

-- 2. Popula√ß√£o com Dados de Exemplo
INSERT INTO bronze.censo (source_file, area_km2, densidade_demografica_hab_km2, renda_total_nominal, populacao_ocupada, sexo, cor_ou_raca) VALUES
-- ... [Dados de Exemplo Omitidos por Brevidade]
```

### 2.2. Transforma√ß√£o SILVER (Limpeza e C√°lculo Cr√≠tico)

```sql
-- Cria a tabela SILVER, realizando a limpeza de tipos e o c√°lculo do rendimento.
DROP TABLE IF EXISTS silver.censo_consolidado_silver CASCADE;
-- ... [C√≥digo SILVER Omitido por Brevidade]
```

### 2.3. Modelagem GOLD (Cria√ß√£o do Star Schema e Agrega√ß√£o)

```sql
-- Cria√ß√£o de Dimens√µes, Tabela Fato e Agrega√ß√£o Final
-- ... [C√≥digo GOLD Omitido por Brevidade]
```

-----

## 3\. Qualidade de Dados e Insights (PySpark/Databricks)

Esta se√ß√£o foca nas rotinas di√°rias de **Auditoria** e **An√°lise**, utilizando PySpark sobre os dados limpos (Silver) e agregados (Gold).

### 3.1. Funcionalidades de Qualidade e Auditoria

As fun√ß√µes de auditoria s√£o vitais para a sustenta√ß√£o do pipeline, garantindo que as regras de ETL foram aplicadas corretamente:

  * **`check_null_counts`:** Rastreia a presen√ßa de valores nulos nas colunas cr√≠ticas (rendimento, popula√ß√£o).
  * **`check_uniqueness`:** Valida a integridade da chave composta (`id_geografia`, `sexo`, `cor_ou_raca`) na camada Silver, evitando duplica√ß√£o de m√©tricas.

### 3.2. Funcionalidades de An√°lise (Business Value)

As fun√ß√µes de an√°lise exploram os *insights* de desigualdade presentes nos dados:

  * **`rank_rendimento_by_sex`:** Permite identificar rapidamente os top N munic√≠pios com maior rendimento para uma determinada categoria (ex: Homens ou Mulheres), direcionando a an√°lise de poder aquisitivo.
  * **`calculate_gender_gap`:** Executa uma an√°lise crucial de disparidade, calculando a diferen√ßa absoluta e a **raz√£o** de rendimento (Homem / Mulher) por geografia. Este *insight* √© fundamental para pol√≠ticas de equidade salarial.

### 3.3. Notebook PySpark (Exemplo de Rotina)

```python
from pyspark.sql.functions import col, avg, round, min, max, count, when, lit, desc, countDistinct, abs
from pyspark.sql.window import Window

# --- 1. FUN√á√ïES DE QUALIDADE E AUDITORIA AVAN√áADA ---

def check_null_counts(df, columns):
    """Auditoria: Contagem de valores NULL em colunas."""
    df.select([count(when(col(c).isNull(), c)).alias(f"NULOS_{c}") for c in columns]).show()

def check_uniqueness(df, column):
    """Auditoria: Verifica a unicidade de uma chave."""
    # ... [C√≥digo Omitido por Brevidade]

# --- 2. FUN√á√ïES DE AN√ÅLISE AVAN√áADA ---

def rank_rendimento_by_sex(df_silver, category='Homens'):
    """An√°lise: Ranqueia as geografias pelo Rendimento M√©dio de uma categoria espec√≠fica (uso de Window Function)."""
    # ... [C√≥digo Omitido por Brevidade]

def calculate_gender_gap(df_silver):
    """An√°lise: Calcula a disparidade de rendimento (homens vs. mulheres) por munic√≠pio e identifica o maior GAP."""
    print("\n--- An√°lise: Maiores Gaps de Rendimento por Munic√≠pio ---")
    
    df_pivot = df_silver.groupBy("id_geografia") \
        .pivot("sexo") \
        .agg(round(avg(col("rendimento_medio_mensal")), 2).alias("rendimento_medio")) \
        .filter(col("Homens").isNotNull() & col("Mulheres").isNotNull())

    df_gap = df_pivot.withColumn(
        "rendimento_gap", 
        col("Homens") - col("Mulheres")
    ).withColumn(
        "razao_homem_mulher", 
        round(col("Homens") / col("Mulheres"), 2)
    )

    df_gap.orderBy(desc("rendimento_gap")) \
          .select("id_geografia", "Homens", "Mulheres", "rendimento_gap", "razao_homem_mulher") \
          .show(3, truncate=False)
```
